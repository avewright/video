data_seed: 42
dataset:
  instruction_template: "You are a professional invoice and receipt data extraction specialist. Analyze the document image and extract ALL information into a precise JSON structure.\n\nEXTRACTION REQUIREMENTS:\n1. Extract company/vendor information from the seller field\n2. Parse the complete address from seller details\n3. Convert date to MM/DD/YYYY format exactly as shown\n4. Extract monetary values maintaining original format (commas as decimals, dollar signs)\n5. Extract ALL line items with complete details\n6. Calculate totals including tax information\n\nOUTPUT FORMAT (JSON only, no other text):\n{\n  \"company\": \"[First 2-3 words of seller/vendor name]\",\n  \"address\": \"[Complete seller address as shown]\",\n  \"date\": \"[Invoice date in MM/DD/YYYY format]\",\n  \"invoice_number\": \"[Invoice/document number]\",\n  \"total\": \"[Final total amount with currency symbol]\",\n  \"tax\": \"[Tax amount with currency symbol]\",\n  \"items\": [\n    {\n      \"description\": \"[Complete item description]\",\n      \"quantity\": \"[Quantity with unit if shown]\",\n      \"unit_price\": \"[Price per unit with decimal comma format]\",\n      \"line_total\": \"[Total for this line item]\",\n      \"vat_rate\": \"[VAT/tax percentage if shown]\"\n    }\n  ]\n}\n\nJSON:"
  name: mychen76/invoices-and-receipts_ocr_v1
  preprocessing:
    image_mean:
    - 0.485
    - 0.456
    - 0.406
    image_std:
    - 0.229
    - 0.224
    - 0.225
    max_image_size: 1280
    min_image_size: 224
  test_split: test
  train_split: train
  validation_split: valid
device: cuda
gradient_checkpointing: true
mixed_precision: bf16
model:
  bnb_4bit_compute_dtype: bfloat16
  bnb_4bit_quant_type: nf4
  bnb_4bit_use_double_quant: true
  load_in_4bit: true
  lora_config:
    bias: none
    lora_alpha: 16
    lora_dropout: 0.05
    r: 8
    target_modules:
    - q_proj
    - v_proj
    - k_proj
    - o_proj
    - gate_proj
    - up_proj
    - down_proj
    task_type: CAUSAL_LM
  model_max_length: 2048
  name: Qwen/Qwen2.5-VL-3B-Instruct
  torch_dtype: bfloat16
  trust_remote_code: true
  use_qlora: true
seed: 42
training:
  adam_beta1: 0.9
  adam_beta2: 0.999
  adam_epsilon: 1.0e-08
  bf16: true
  dataloader_num_workers: 0
  eval_steps: 25
  evaluation_strategy: steps
  fp16: false
  gradient_accumulation_steps: 8
  gradient_checkpointing: true
  greater_is_better: false
  learning_rate: 0.0002
  load_best_model_at_end: true
  logging_steps: 5
  logging_strategy: steps
  lr_scheduler_type: cosine
  max_grad_norm: 1.0
  max_steps: -1
  metric_for_best_model: eval_loss
  num_train_epochs: 3
  optim: adamw_torch
  output_dir: ./outputs/qwen25-3b-qlora-invoice
  overwrite_output_dir: true
  per_device_eval_batch_size: 1
  per_device_train_batch_size: 1
  remove_unused_columns: false
  report_to:
  - tensorboard
  save_steps: 25
  save_strategy: steps
  save_total_limit: 3
  warmup_ratio: 0.03
  warmup_steps: 100
  weight_decay: 0.01
